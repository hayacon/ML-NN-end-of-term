{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of term coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project follows the universal workflow of machine learning from DLWP 4.5 (p.111). <br>\n",
    "Based on this workflow, the project first needs to define the problem and assembling the dataset. The problem that this project trying to solve is the multiclass image classification of fashion items. More specifically, it is single label, multiclass classfication since each data should be classfied into one category, fashion item.\n",
    "This project will develop the ML model that will classify the type of fashion item. The inputs to the model will be the image of a fashion item and the output will be the type or label of a fashion item such as trousers or dress.\n",
    "This project will be using the dataset \"fashion_mnist\"(https://www.tensorflow.org/datasets/catalog/fashion_mnist) from TensorFlow Dataset.  When building an ML model, there are few problems that I need to be aware of. One example is nonstationary problems can occur when a model is trying to predict something dependent on the season. For example, making fashion recommendations for winter based on the data from August will not work. However, the problem for this project is stationary and nonstationary problems will not apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measure of success for this problem will be accuracy. How accurate the model can classify the fashion item will be the most important. The model will choose the loss function based on this measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned, I will be using \"fashion_mnist\" dataset (https://www.tensorflow.org/datasets/catalog/fashion_mnist) from TensorFlow Dataset.<br>\n",
    "The dataset is designed the same way as MNIST dataset. It consists of 60,000 grayscale images of 28x28 pixels and additional 10,000images for the test. Therefore, I can hypothesize that my output can be predicted from the input which is the image of a fashion item and the dataset is informative enough for the model to learn relationships between inputs image and output label.<br>\n",
    "To use the dataset from the TensorFlow dataset, I need to install the following package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the stable version of the TensorFlow dataset package. There is another version that updates datasets daily but that is not required for this project and a stable version is more suitable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all necessary packages for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessaru modlues for this projecrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the dataset can be load to this project with the following code. \n",
    "```python \n",
    "ds = tfds.load('fashion_mnist', split, shuffle_files)\n",
    "```\n",
    "The split argument will determine how to split the dataset, and the shuffle_files argument specifies whether shullfle the dataset or not. These will be specifies as train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data needs to be ready to fed into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TensorFlow dataset for taining a neural network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'fashion_mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the detail information about this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    full_name='fashion_mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    data_path='/Users/kyonkyon/tensorflow_datasets/fashion_mnist/3.0.1',\n",
       "    download_size=29.45 MiB,\n",
       "    dataset_size=36.42 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_train 60000\n",
      "ds_test 10000\n"
     ]
    }
   ],
   "source": [
    "print('ds_train', len(ds_train))\n",
    "print('ds_test', len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refrence :<br> TensorFlow dataset https://www.tensorflow.org/datasets/keras_example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model, I will use Keras. Since it is already included in TensorFlow module, there is no need for importing other modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(64,activation='relu'),\n",
    "  tf.keras.layers.Dense(46, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2925 - sparse_categorical_accuracy: 0.8926 - val_loss: 0.3542 - val_sparse_categorical_accuracy: 0.8736\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2858 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.8785\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2796 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.3503 - val_sparse_categorical_accuracy: 0.8770\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2785 - sparse_categorical_accuracy: 0.8994 - val_loss: 0.3532 - val_sparse_categorical_accuracy: 0.8753\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2728 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.3473 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3522 - val_sparse_categorical_accuracy: 0.8763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refrence :<br> TensorFLow dataset https://www.tensorflow.org/datasets/keras_example <br>\n",
    "DLWP 3.5 \"Classifying newswires: a multiclass classification example\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a result of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-6f2b69d28794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-effe661a7a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
